{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from numpy.linalg import inv\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'BostonDataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dataset into a pandas dataframe\n",
    "data_frame = pd.read_csv(dataset_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM         ZN       INDUS         CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
       "\n",
       "             MEDV  \n",
       "count  506.000000  \n",
       "mean    22.532806  \n",
       "std      9.197104  \n",
       "min      5.000000  \n",
       "25%     17.025000  \n",
       "50%     21.200000  \n",
       "75%     25.000000  \n",
       "max     50.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', ' ZN ', 'INDUS ', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'LSTAT', 'MEDV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe to np array\n",
    "data_array = data_frame.to_numpy()\n",
    "print(data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define linear regression\n",
    "def linear_regression_fit(X,Y):\n",
    "    return inv(X.T@X)@X.T@Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_with_bias_fit(X,Y):\n",
    "    return (inv(X.T@X)@X.T@Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 33.0% of the dataset dor testing and the rest 67.0% for the training\n"
     ]
    }
   ],
   "source": [
    "# number of runs for each experiment (defined on the assignement paper)\n",
    "N = 20\n",
    "features_number = 13\n",
    "test_split = round(((len(data_array)/3)/len(data_array)*100)/100,2)\n",
    "print(\"Using \" + str(test_split*100) + \"% of the dataset dor testing and the rest \" + str(round((1 - test_split),2)*100) + \"% for the training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization!\n",
      "Average MSE for train and test set are: 77.03490275928681 and 99.71760814810197 respectively\n"
     ]
    }
   ],
   "source": [
    "# (a) Predicting with the mean y-value on the training set\n",
    "# question 1.2.a\n",
    "for i in range(0,N):\n",
    "    \n",
    "    # split data on train and test set\n",
    "    # suffle = True by default in this sklearn function\n",
    "    train_data, test_data = train_test_split(data_array,test_size=test_split)\n",
    "\n",
    "    if(i==0):\n",
    "        ## initialize on the first round\n",
    "        print(\"Initialization!\")\n",
    "        ## initialize x vectors with ones - fit the data with constant function\n",
    "        x_train = np.asmatrix(np.ones(len(train_data))).T\n",
    "        x_test = np.asmatrix(np.ones(len(test_data))).T\n",
    "        y_train = train_data[:,(features_number-1)]\n",
    "        y_test = test_data[:,(features_number-1)]\n",
    "        mse_train = np.zeros(N)\n",
    "        mse_test = np.zeros(N)\n",
    "    \n",
    "    w_train = linear_regression_fit(x_train,y_train)\n",
    "    w_test = linear_regression_fit(x_test,y_test)\n",
    "    \n",
    "    mse_train[i]= mean_squared_error(x_train*w_train, y_train)\n",
    "    mse_test[i]= mean_squared_error(x_test*w_train, y_test)\n",
    "    \n",
    "print(\"Average MSE for train and test set are: \" + str(np.mean(mse_train)) + \" and \" + str(np.mean(mse_test)) + \" respectively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with single Features - Results\n",
      "Linear regression using attribute: CRIM MSE train: 73.28153218461637 MSE test:65.65195838885228\n",
      "Linear regression using attribute:  ZN  MSE train: 75.22689431904232 MSE test:68.96448136724034\n",
      "Linear regression using attribute: INDUS  MSE train: 67.12326214391811 MSE test:59.01029698892465\n",
      "Linear regression using attribute: CHAS MSE train: 84.00658810550773 MSE test:76.21965921795861\n",
      "Linear regression using attribute: NOX MSE train: 71.74644738326911 MSE test:62.632150499587\n",
      "Linear regression using attribute: RM MSE train: 44.91671265470207 MSE test:39.72961122113274\n",
      "Linear regression using attribute: AGE MSE train: 75.4777590707787 MSE test:65.28953503879058\n",
      "Linear regression using attribute: DIS MSE train: 82.05386912259577 MSE test:72.33358761183362\n",
      "Linear regression using attribute: RAD MSE train: 74.34580712493519 MSE test:66.81485613779624\n",
      "Linear regression using attribute: TAX MSE train: 68.27657730932647 MSE test:60.1512311019966\n",
      "Linear regression using attribute: PTRATIO MSE train: 63.85698722496212 MSE test:59.202656070663046\n",
      "Linear regression using attribute: LSTAT MSE train: 39.9203895051604 MSE test:34.915791613974626\n"
     ]
    }
   ],
   "source": [
    "## (b) Predicting with a single attribute and a bias term.\n",
    "mse_train = np.zeros((N,(features_number-1)))\n",
    "mse_test = np.zeros((N,(features_number-1)))\n",
    "\n",
    "for i in range(0,N):\n",
    "    \n",
    "    train_data, test_data = train_test_split(data_array,test_size=test_split)\n",
    "        \n",
    "    for j in range(0,(features_number-1)):\n",
    "        \n",
    "      \n",
    "        y_train = train_data[:,(features_number-1)]\n",
    "        y_test = test_data[:,(features_number-1)]\n",
    "        \n",
    "        ## select one feature on every loop\n",
    "        ## and one extra dimension with 1 values on the x\n",
    "        x_train = np.asmatrix(np.vstack((train_data[:,j],np.ones(len(train_data))))).T\n",
    "        x_test = np.asmatrix(np.vstack((test_data [:,j],np.ones(len(test_data))))).T\n",
    "        \n",
    "        w_train = linear_regression_with_bias_fit(x_train,y_train)\n",
    "        w_test = linear_regression_with_bias_fit(x_test,y_test)\n",
    "       \n",
    "        mse_train[i,j]= mean_squared_error(x_train@w_train, y_train)\n",
    "        mse_test[i,j]= mean_squared_error(x_test@w_test, y_test)\n",
    "        \n",
    "print(\"Linear Regression with single Features - Results\")   \n",
    "for i in range(len(mse_train.T)):\n",
    "    print(\"Linear regression using attribute: \" + str(data_frame.columns[i]) + \" MSE train: \" + str(np.mean((np.sum(mse_train,axis = 0)/N).T[i])) +\" MSE test:\" + str(np.mean((np.sum(mse_test,axis = 0 )/N).T[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression using all the features with MSE train: 1.4084329525873831e-24 MSE test: 5.171647149926117e-25\n"
     ]
    }
   ],
   "source": [
    "## Predicting with all the attributes\n",
    "for i in range(N):\n",
    "    \n",
    "    mse_train = np.zeros(N)\n",
    "    mse_test  = np.zeros(N)\n",
    "    \n",
    "    train_data, test_data = train_test_split(data_array,test_size=test_split)\n",
    "     \n",
    "    ## use all the features\n",
    "    y_train = train_data[:,(features_number-1)]\n",
    "    y_test = test_data[:,(features_number-1)]\n",
    "    \n",
    "    ## add one dimension with one to x data\n",
    "    x_train = np.asmatrix(np.c_[(train_data[:,range(features_number)],np.ones(len(train_data)))])\n",
    "    x_test = np.asmatrix(np.c_[(test_data[:,range(features_number)] ,np.ones(len(test_data )))])\n",
    "        \n",
    "    w_train = linear_regression_with_bias_fit(x_train,y_train)\n",
    "    w_test = linear_regression_with_bias_fit(x_test,y_test)\n",
    "        \n",
    "    mse_train[i]= mean_squared_error(x_train@w_train, y_train)\n",
    "    mse_test [i]= mean_squared_error(x_test@w_test, y_test)\n",
    "        \n",
    "print(\"Linear regression using all the features with MSE train: \" + str(np.sum(mse_train)/N) + \" MSE test: \" +  str(np.sum(mse_test )/N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
